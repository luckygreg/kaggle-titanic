{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas, Numpy, Scikit-learn 練習 2 \n",
    "## Kaggle Titanic: Machine Learning from Disaster\n",
    "\n",
    "學習內容:\n",
    " * 用統計方法填充NaN或缺失值\n",
    " * 數據類型轉換: Dummy variables\n",
    " * 模型調參數: GridSearchCV\n",
    " * 提交submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandasql import sqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop(['Name', 'Cabin', 'Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "填充NaN的方法有很多，簡單的有以下幾種:\n",
    "------\n",
    "\n",
    "如果是數值類型，可以用\n",
    "1. mean, 平均數\n",
    "2. median, 中位數\n",
    "3. mode, 最常出現數\n",
    "\n",
    "如果是字符類型，可以用\n",
    "1. mode, 最常出現字符\n",
    "\n",
    "\n",
    "### Mode Returns\n",
    "mode : ndarray\n",
    "    Array of modal values.\n",
    "count : ndarray\n",
    "    Array of counts for each mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobiaslei/dev/ml/env/lib/python2.7/site-packages/scipy/stats/stats.py:253: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n",
      "/Users/tobiaslei/dev/ml/env/lib/python2.7/site-packages/numpy/lib/arraysetops.py:216: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "mean_age = train['Age'].mean()\n",
    "train['Age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "mode_embarked = mode(train['Embarked'])[0][0]\n",
    "train['Embarked'].fillna(mode_embarked, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q']\n",
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "print train['Embarked'].unique()\n",
    "print train['Sex'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為Embarked是有分類字段，如果轉換成0, 1, 2就代表S < C < Q的關係。實際上我們並不想這樣，所以我們為每個分類單獨建一個feature。\n",
    "\n",
    "* Embarked_S: {0, 1} \n",
    "* Embarked_C: {0, 1}\n",
    "* Embarked_Q: {0, 1}\n",
    "\n",
    "pandas提供這種轉換的功能. pd.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked_C  Embarked_Q  Embarked_S\n",
       "0           0           0           1\n",
       "1           1           0           0\n",
       "2           0           0           1\n",
       "3           0           0           1\n",
       "4           0           0           1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(train['Embarked'], prefix='Embarked').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_embarked = pd.get_dummies(train['Embarked'], prefix='Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train, dummy_embarked], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['sex_num'] = train['Sex'].map({'male': 0, 'female': 1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['Embarked', 'Sex'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'sex_num']\n"
     ]
    }
   ],
   "source": [
    "print cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train[[cols[0]] + cols[2:] + [cols[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分 trian_sample / test_sample兩份數據\n",
    "----\n",
    "因為真正的 test data, 我們是沒有真正的預測label, 所以我們只能從train_data裡分出一部份數據來進行測試預測結果\n",
    "\n",
    "train_sample: 會用來調模型參數\n",
    "\n",
    "test_sample: 會用來測試模型效果\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "idx = np.array(range(train_data.shape[0]))\n",
    "random.shuffle(idx)\n",
    "split_n = int(train_data.shape[0] * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sample = train_data[idx[:split_n]]\n",
    "test_sample = train_data[idx[split_n:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "891\n"
     ]
    }
   ],
   "source": [
    "print train_sample.shape[0] + test_sample.shape[0]\n",
    "print train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型調參數\n",
    "\n",
    "Random Forest內置有很多參數可以調，GridSearchCV提供了方法讓我們可以去用已有的數據找到最好的參數。\n",
    "\n",
    "Random Forest是由好多棵樹組成：\n",
    "1. 每個樹用了多少個feature是由max_feature控制的。默認值是'auto', max_features=sqrt(n_features)\n",
    "2. 森林的層數是由max_depth來控制。默認值是None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "\n",
    "我們想通過grid_search去找到最合理的max_features和max_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(RandomForestClassifier(), \n",
    "                           cv=5,\n",
    "                           n_jobs=10,\n",
    "                           param_grid={'n_estimators': [10, 300],\n",
    "                                       'max_features': ['sqrt', 'log2', None],\n",
    "                                       'max_depth': [5, 10, None]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=10,\n",
       "       param_grid={'n_estimators': [10, 300], 'max_features': ['sqrt', 'log2', None], 'max_depth': [5, 10, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_sample[:, :-1], train_sample[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.828964\n",
      "Best params: {'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "print 'Best Score: %f' % grid_search.best_score_\n",
    "print 'Best params: %s' % grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = RandomForestClassifier(**{'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 10})    \n",
    "m = m.fit(train_sample[:, :-1], train_sample[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = m.predict(test_sample[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_sample[:, :-1]\n",
    "y = train_sample[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777777777778\n",
      "0.8\n",
      "0.75\n",
      "0.8\n",
      "0.8\n",
      "0.85\n",
      "0.8375\n",
      "0.8625\n",
      "0.8875\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    m = RandomForestClassifier(**{'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 10, 'max_depth': 10})    \n",
    "    m = m.fit(X_train, y_train)\n",
    "    r = m.predict(X_test)\n",
    "    print np.sum(r==y_test) / float(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755555555556\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestClassifier(**{'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 10, 'max_depth': 10})    \n",
    "m = m.fit(X, y)\n",
    "r = m.predict(test_sample[:, :-1])\n",
    "print np.sum(r==test_sample[:, -1]) / float(test_sample.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    df.drop(['Cabin', 'Ticket', 'Name'], axis=1, inplace=True)\n",
    "    df['Age'].fillna(mean_age, inplace=True)\n",
    "    df['Fare'].fillna(df['Fare'].mean(), inplace=True)\n",
    "    df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1)\n",
    "    df['sex_num'] = df['Sex'].map({'male': 0, 'female': 1}).astype(int)\n",
    "    df.drop(['Embarked', 'Sex'], axis=1, inplace=True)\n",
    "    return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/titanic/test.csv')\n",
    "test_data = preprocessing(test)\n",
    "result = m.predict(test_data)\n",
    "out = pd.DataFrame(data=zip(test_data[:, 0].astype(int), result.astype(int)), columns=['PassengerId', 'Survived'])\n",
    "out.to_csv('titanic2_2_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!open titanic2_2_out.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提交submission! yay!\n",
    "\n",
    "https://www.kaggle.com/c/titanic/submissions/attach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
